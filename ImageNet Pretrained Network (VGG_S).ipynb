{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This example demonstrates using a network pretrained on ImageNet for classification. The model used was converted from the VGG_CNN_S model (http://arxiv.org/abs/1405.3531) in [Caffe's Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo). \n",
    "\n",
    "For details of the conversion process, see the example notebook \"Using a Caffe Pretrained Network - CIFAR10\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "The model is licensed for non-commercial use only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the model (393 MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "#!wget https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg_cnn_s.pkl\n",
    "import sys\n",
    "sys.path.append('../../coco/PythonAPI')\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "from numpy import reshape\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "#modulename = importlib.machinery.SourceFileLoader('modulename','/Path/To/module.py').load_module()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../../coco/annotations/instances_train2014.json') as data_file:\n",
    "    data = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=16.97s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=10.20s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataDir='../../coco'\n",
    "dataType='train2014'\n",
    "annFile='%s/annotations/instances_%s.json'%(dataDir,dataType)\n",
    "cocoTrain=COCO(annFile)\n",
    "dataType='val2014'\n",
    "annFile='%s/annotations/instances_%s.json'%(dataDir,dataType)\n",
    "cocoVal=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define a function which can read images, resize them to height x width and save the resized image in place of the original\n",
    "from PIL import Image\n",
    "def resizer(directory,width,height):\n",
    "    i = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if i%1000 == 0:\n",
    "            print(i)\n",
    "        # Open the image file.\n",
    "        img = Image.open(os.path.join(directory, filename))\n",
    "        # Resize it.\n",
    "        img = img.resize((width, height), Image.BILINEAR)\n",
    "        # Save it back to disk.\n",
    "        img.save(os.path.join(directory, filename))\n",
    "        i += 1\n",
    "    print('Batch processing complete.')\n",
    "#resizer('../../coco/train2014',224,224)\n",
    "#resizer('../../coco/val2014',224,224)\n",
    "#resizer('../../coco/test2014',224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define a function which checks if images have dimensions (height, width,3). If not, delete the image\n",
    "def wrongShapeDeleter(directory, height, width):\n",
    "    counter = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        img = io.imread('%s/%s'%(directory,filename))\n",
    "        if img.shape != (height, width, 3):\n",
    "            counter += 1\n",
    "            #If the image has some other shape than (height, width), i.e. grayscale, we want to see it\n",
    "            if img.shape != (height, width):\n",
    "                print(filename, img.shape)\n",
    "            else:\n",
    "                os.remove('%s/%s'%(directory,filename))\n",
    "    print directory, counter\n",
    "#wrongShapeDeleter('../../coco/train2014',224,224)\n",
    "#wrongShapeDeleter('../../coco/val2014',224,224)\n",
    "#wrongShapeDeleter('../../coco/test2014',224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]\n"
     ]
    }
   ],
   "source": [
    "cats = cocoTrain.loadCats(cocoTrain.getCatIds())\n",
    "#print(cats)\n",
    "validCatIds = [x['id'] for x in cats]\n",
    "print(validCatIds)\n",
    "yo = cocoTrain.loadImgs(185652)\n",
    "#print(yo[0]['id'])\n",
    "yo2 = cocoTrain.loadAnns(ids=[185652])\n",
    "#print(yo2[0]['category_id'])\n",
    "yoyo = cocoTrain.getImgIds()\n",
    "#print(yo2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Some image files have been deleted by us because they only contained 1 channel. \n",
    "#However, the function coco.getImgIds doesn't \"know\" this. \n",
    "#Therefore we must have a list of which files have been deleted.\n",
    "def deletedFileLister(directory,coco):\n",
    "    existingFileNames = os.listdir(directory)\n",
    "    allImgIds = coco.getImgIds()\n",
    "    deletedFileNames = []\n",
    "    for i in range(len(allImgIds)):\n",
    "        if i%1000==0:\n",
    "            print i\n",
    "        tempImg = coco.loadImgs(allImgIds[i])\n",
    "        if not(tempImg[0]['file_name'] in existingFileNames):\n",
    "            deletedFileNames.append(tempImg[0]['file_name'])\n",
    "    return deletedFileNames\n",
    "\n",
    "#trainDeletedFiles = deletedFileLister('../../coco/train2014', cocoTrain)\n",
    "#valDeletedFiles = deletedFileLister('../../coco/val2014', cocoVal)\n",
    "\n",
    "import pickle\n",
    "#with open('listsOfDeletedFiles','w') as f:\n",
    "#    pickle.dump([trainDeletedFiles,valDeletedFiles],f)\n",
    "allDeletedFiles = pickle.load(open('listsOfDeletedFiles', 'rb'))\n",
    "trainDeletedFiles = allDeletedFiles[0]\n",
    "valDeletedFiles = allDeletedFiles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getXandY(coco,minimumCatCount,validCatIds,fileDirectory,deletedFileNames):\n",
    "    allFileNames = os.listdir(fileDirectory)\n",
    "    allImgIds = coco.getImgIds()\n",
    "    singleCatImgIds = []\n",
    "    allAnnIds = coco.getAnnIds(imgIds=allImgIds);\n",
    "    myDict = {}\n",
    "    counter = 0\n",
    "    for i in range(len(allImgIds)):\n",
    "        #tempAnns = coco.loadAnns(ids=allAnnIds[i])\n",
    "        tempAnns = coco.loadAnns(coco.getAnnIds(imgIds=allImgIds[i]))\n",
    "        tempImg = coco.loadImgs(allImgIds[i])\n",
    "        #if(\"train\" in tempImg[0]['file_name']):\n",
    "        #    print \"Brarp brarp\",allImgIds[i], tempImg[0]['file_name']\n",
    "        allCategoriesList = []\n",
    "        #Find all categories associated with the current image\n",
    "        for x in tempAnns:\n",
    "            allCategoriesList.append(x['category_id'])\n",
    "        allCategoriesList = set(allCategoriesList)\n",
    "        #Images are included in training or validation set if they are associated with exactly one category \n",
    "        #and if they have not been deleted.\n",
    "        if len(allCategoriesList)==1 and not(tempImg[0]['file_name'] in deletedFileNames):\n",
    "            counter += 1\n",
    "            myDict[allImgIds[i]] = [tempAnns[0]['category_id'], tempImg[0]['file_name']]\n",
    "            singleCatImgIds.append(allImgIds[i])\n",
    "    allSingleCategories = [x[0] for x in list(myDict.values())]\n",
    "    categoryCounts = {x:allSingleCategories.count(x) for x in validCatIds}\n",
    "    plentifulCategories = [x for x in validCatIds if categoryCounts[x]>=minimumCatCount]\n",
    "    plentifulCategoryCounts = {x:categoryCounts[x] for x in plentifulCategories}\n",
    "    plentifulImageIds = [x for x in list(myDict.keys()) if myDict[x][0] in plentifulCategories]\n",
    "    plentifulDict = {k:myDict[k] for k in plentifulImageIds}\n",
    "    return [plentifulDict, plentifulCategories, plentifulCategoryCounts]\n",
    "\n",
    "trainList = getXandY(cocoTrain, 100, validCatIds, '../../coco/train2014', trainDeletedFiles)\n",
    "trainDict = trainList[0]\n",
    "#The validation set should only contain categories which are also in the training set. \n",
    "#Therefore we pass the category ids from the training set as validCatIds\n",
    "valList = getXandY(cocoVal, 50, trainList[1], '../../coco/val2014', valDeletedFiles)\n",
    "valDict = valList[0]\n",
    "num_classes = len(trainList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in training set: 15423\n",
      "Number of images in validation set: 7701\n",
      "Training and val. set have the same categories: True\n"
     ]
    }
   ],
   "source": [
    "print \"Number of images in training set:\",len(trainList[0]) \n",
    "print \"Number of images in validation set:\",len(valList[0])\n",
    "#Ensure that validation does not have less categories than training set\n",
    "print \"Training and val. set have the same categories:\", trainList[1]==valList[1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataDir = \"../../coco\"\n",
    "dataType = \"../../coco\"\n",
    "allFiles = os.listdir('../../coco/train2014')\n",
    "height = 224\n",
    "width = 224\n",
    "N = 1\n",
    "x_train = []\n",
    "x_train = np.empty([N,3,height,width])\n",
    "i = 0\n",
    "j = 0\n",
    "for filename in allFiles:\n",
    "    i += 1\n",
    "    if i>N-1:\n",
    "        break\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    #print(i)\n",
    "    I = io.imread('%s/%s/%s'%(dataDir,'train2014',filename))\n",
    "    if I.shape == (height, width, 3):\n",
    "        x_train[j,:,:,:] = np.transpose(I,(2,0,1))\n",
    "        j += 1\n",
    "    else:\n",
    "        print(\"yo\",i)\n",
    "    #x_train[i,:,:,:] = np.transpose(io.imread('%s/%s/%s'%(dataDir,'train2014',filename)),(2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(x_train.shape)\n",
    "#plt.figure()\n",
    "#plt.imshow(I[0,:,:])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import InputLayer, DenseLayer, DropoutLayer\n",
    "from lasagne.layers.dnn import Conv2DDNNLayer as ConvLayer\n",
    "from lasagne.layers import MaxPool2DLayer as PoolLayer\n",
    "from lasagne.layers import LocalResponseNormalization2DLayer as NormLayer\n",
    "from lasagne.utils import floatX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = {}\n",
    "net['input'] = InputLayer((None, 3, 224, 224))\n",
    "net['conv1'] = ConvLayer(net['input'], num_filters=96, filter_size=7, stride=2, flip_filters=False)\n",
    "net['norm1'] = NormLayer(net['conv1'], alpha=0.0001) # caffe has alpha = alpha * pool_size\n",
    "net['pool1'] = PoolLayer(net['norm1'], pool_size=3, stride=3, ignore_border=False)\n",
    "net['conv2'] = ConvLayer(net['pool1'], num_filters=256, filter_size=5, flip_filters=False)\n",
    "net['pool2'] = PoolLayer(net['conv2'], pool_size=2, stride=2, ignore_border=False)\n",
    "net['conv3'] = ConvLayer(net['pool2'], num_filters=512, filter_size=3, pad=1, flip_filters=False)\n",
    "net['conv4'] = ConvLayer(net['conv3'], num_filters=512, filter_size=3, pad=1, flip_filters=False)\n",
    "net['conv5'] = ConvLayer(net['conv4'], num_filters=512, filter_size=3, pad=1, flip_filters=False)\n",
    "net['pool5'] = PoolLayer(net['conv5'], pool_size=3, stride=3, ignore_border=False)\n",
    "net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "net['drop6'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "net['fc7'] = DenseLayer(net['drop6'], num_units=4096)\n",
    "net['drop7'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "#net['fc8'] = DenseLayer(net['drop7'], num_units=1000, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "net['fc8Modified'] = DenseLayer(net['drop7'], num_units=num_classes, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "output_layer = net['fc8Modified']\n",
    "#output_layer = net['pool5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, (18432, 4096))\n",
      "(11, (4096,))\n",
      "(12, (4096, 4096))\n",
      "(13, (4096,))\n",
      "\n",
      "(0, (96, 3, 7, 7))\n",
      "(1, (96,))\n",
      "(2, (256, 96, 5, 5))\n",
      "(3, (256,))\n",
      "(4, (512, 256, 3, 3))\n",
      "(5, (512,))\n",
      "(6, (512, 512, 3, 3))\n",
      "(7, (512,))\n",
      "(8, (512, 512, 3, 3))\n",
      "(9, (512,))\n",
      "(10, (18432, 4096))\n",
      "(11, (4096,))\n",
      "(12, (4096, 4096))\n",
      "(13, (4096,))\n",
      "(14, (4096, 35))\n",
      "(15, (35,))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model = pickle.load(open('vgg_cnn_s.pkl'))\n",
    "CLASSES = model['synset words']\n",
    "MEAN_IMAGE = model['mean image']\n",
    "for i in range(10,len(model['values'])-2):\n",
    "    print(i, model['values'][i].shape)\n",
    "    model['values'][i].fill(0)\n",
    "    \n",
    "# If we do not cast to float32 we get this error: \n",
    "#TypeError: ('CudaNdarrayType(float32, vector), with dtype float32, \n",
    "#cannot store a value of dtype float64 without risking loss of precision.\n",
    "#If you do not mind, please cast your data to float32.'\n",
    "model['values'][14] = np.random.normal(0,1,(4096,num_classes)).astype(np.float32)\n",
    "model['values'][15] = np.random.normal(0,1,(num_classes,)).astype(np.float32)\n",
    "\n",
    "#lasagne.layers.set_all_param_values(output_layer, model['values'])\n",
    "#lasagne.layers.set_all_param_values(output_layer, model[\"values\"][0:10])\n",
    "print('')\n",
    "for i in range(len(model['values'])):\n",
    "    print(i, model['values'][i].shape)\n",
    "lasagne.layers.set_all_param_values(output_layer, model['values'])\n",
    "#lasagne.layers.get_all_param_values(output_layer)\n",
    "#lasagne.layers.set_all_param_values(output_layer, model[\"values\"][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "#Setting up the graph in theano\n",
    "sym_x = T.tensor4('sym_x') # a symbolic variable, this is now a 4-D tensor.\n",
    "sym_t = T.ivector('sym_t') # a symbolic variable taking on the value of the target batch.\n",
    "\n",
    "# Retrieve network output\n",
    "train_out = lasagne.layers.get_output(output_layer, sym_x, deterministic=False)\n",
    "eval_out = lasagne.layers.get_output(output_layer, sym_x, deterministic=True)\n",
    "\n",
    "# Retrieve list of all trainable parameters in the network.\n",
    "all_params = lasagne.layers.get_all_params(output_layer, trainable=True)\n",
    "\n",
    "#Define our cost function\n",
    "cost = T.nnet.categorical_crossentropy(train_out+1e-8, sym_t).mean()\n",
    "\n",
    "# Let Theano do its magic and get all the gradients we need for training\n",
    "all_grads = T.grad(cost, all_params)\n",
    "\n",
    "# Set the update function for parameters \n",
    "updates = lasagne.updates.adam(all_grads, all_params, learning_rate=0.005)\n",
    "\n",
    "#f_val takes x and t and passes them to the cost function.\n",
    "f_val = theano.function([sym_x, sym_t],\n",
    "                         [cost],on_unused_input='warn')\n",
    "\n",
    "f_eval = theano.function([sym_x],\n",
    "                     eval_out, on_unused_input='warn')\n",
    "\n",
    "f_train = theano.function([sym_x, sym_t],\n",
    "                          [cost],\n",
    "                          updates=updates, on_unused_input='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('l_out', (1, 35))\n",
      "[[ 0.00573412  0.00189851  0.05137583  0.05160396  0.03242445  0.0148798\n",
      "   0.02084348  0.04799204  0.01843948  0.00634624  0.01365648  0.01311927\n",
      "   0.02339642  0.11741142  0.00976253  0.01768353  0.01453859  0.05489423\n",
      "   0.01004529  0.00449029  0.02105397  0.00550207  0.05112619  0.02883563\n",
      "   0.05774292  0.00480784  0.04062595  0.00292632  0.0969478   0.01547325\n",
      "   0.01732507  0.01887388  0.05096025  0.00173963  0.05552327]]\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "#Test the forward pass\n",
    "x = np.random.normal(0,1, (1, 3,224,224)).astype('float32') #dummy data\n",
    "\n",
    "model = lasagne.layers.get_output(output_layer, sym_x)\n",
    "out = model.eval({sym_x:x}) #this could also include mask etc if used\n",
    "print(\"l_out\", out.shape)\n",
    "print(out)\n",
    "print(len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create dict which goes from category ID to target vector\n",
    "plentifulCategories = trainList[1]\n",
    "targets = np.arange(len(plentifulCategories)).astype(np.int32)\n",
    "catIdToTargetDict = {x:y for x, y in zip(plentifulCategories, targets)}\n",
    "#for i in range(len(plentifulCategories)):\n",
    "#    target = np.zeros(len(plentifulCategories))\n",
    "#    target[i] = 1\n",
    "#    catIdToTargetDict[plentifulCategories[i]] = target\n",
    "\n",
    "#Create function which reads images based on file names and puts them all into a numpy array\n",
    "def imgReader(directory, fileNames, imageShape, MEAN_IMAGE):\n",
    "    imgArray = np.zeros((len(fileNames),imageShape[0],imageShape[1],imageShape[2]))\n",
    "    for i in range(len(fileNames)):\n",
    "        img = io.imread('%s/%s'%(directory,fileNames[i]))\n",
    "        img = np.transpose(img,(2,0,1))\n",
    "        imgArray[i,:,:,:] = img - MEAN_IMAGE\n",
    "    return imgArray.astype(np.float32)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "6.49350649351\n",
      "12.987012987\n",
      "19.4805194805\n",
      "25.974025974\n",
      "32.4675324675\n",
      "38.961038961\n",
      "45.4545454545\n",
      "51.9480519481\n",
      "58.4415584416\n",
      "64.9350649351\n",
      "71.4285714286\n",
      "77.9220779221\n",
      "84.4155844156\n",
      "90.9090909091\n",
      "97.4025974026\n",
      "1 loop done\n",
      "0.0\n",
      "3.24675324675\n",
      "6.49350649351\n",
      "9.74025974026\n",
      "12.987012987\n",
      "16.2337662338\n",
      "19.4805194805\n",
      "22.7272727273\n",
      "25.974025974\n",
      "29.2207792208\n",
      "32.4675324675\n",
      "35.7142857143\n",
      "38.961038961\n",
      "42.2077922078\n",
      "45.4545454545\n",
      "48.7012987013\n",
      "51.9480519481\n",
      "55.1948051948\n",
      "58.4415584416\n",
      "61.6883116883\n",
      "64.9350649351\n",
      "68.1818181818\n",
      "71.4285714286\n",
      "74.6753246753\n",
      "77.9220779221\n",
      "81.1688311688\n",
      "84.4155844156\n",
      "87.6623376623\n",
      "90.9090909091\n",
      "94.1558441558\n",
      "97.4025974026\n",
      "2 loop done\n",
      "0.0\n",
      "6.49350649351\n",
      "12.987012987\n",
      "19.4805194805\n",
      "25.974025974\n",
      "32.4675324675\n",
      "38.961038961\n",
      "45.4545454545\n",
      "51.9480519481\n",
      "58.4415584416\n",
      "64.9350649351\n",
      "71.4285714286\n",
      "77.9220779221\n",
      "84.4155844156\n",
      "90.9090909091\n",
      "97.4025974026\n",
      "103.896103896\n",
      "110.38961039\n",
      "116.883116883\n",
      "123.376623377\n",
      "129.87012987\n",
      "136.363636364\n",
      "142.857142857\n",
      "149.350649351\n",
      "155.844155844\n",
      "162.337662338\n",
      "168.831168831\n",
      "175.324675325\n",
      "181.818181818\n",
      "188.311688312\n",
      "194.805194805\n",
      "3 loop done\n",
      "0.0\n",
      "6.49350649351\n",
      "12.987012987\n",
      "19.4805194805\n",
      "25.974025974\n",
      "32.4675324675\n",
      "38.961038961\n",
      "45.4545454545\n",
      "51.9480519481\n",
      "58.4415584416\n",
      "64.9350649351\n",
      "71.4285714286\n",
      "77.9220779221\n",
      "84.4155844156\n",
      "90.9090909091\n",
      "97.4025974026\n",
      "4 loop done\n",
      "Epoch 1 : Train Loss 2.119914e+01 , Train acc 0.070455,  Valid acc 0.059091 \n",
      "0.0\n",
      "6.49350649351\n",
      "12.987012987\n",
      "19.4805194805\n",
      "25.974025974\n",
      "32.4675324675\n",
      "38.961038961\n",
      "45.4545454545\n",
      "51.9480519481\n",
      "58.4415584416\n",
      "64.9350649351\n",
      "71.4285714286\n",
      "77.9220779221\n",
      "84.4155844156\n",
      "90.9090909091\n",
      "97.4025974026\n",
      "1 loop done\n",
      "0.0\n",
      "3.24675324675\n",
      "6.49350649351\n",
      "9.74025974026\n",
      "12.987012987\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-88e3ff6513a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Val Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3160\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3161\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3162\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1818\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1819\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must have same first dimension\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y can be no greater than 2-D\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAFyCAYAAAA52erNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nae77k8z3tQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3eb5c3f490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFkCAYAAACuFXjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLrEAAHSJBQCgSywAAF1iAQDo+v95F8OJyG8KGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ed544bc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training Loop\n",
    "from confusionmatrix import ConfusionMatrix\n",
    "batch_size = 50\n",
    "batch_size_valid = 10\n",
    "num_epochs = 4\n",
    "num_samples_train = len(trainDict)#x_train.shape[0]\n",
    "num_batches_train = num_samples_train // batch_size\n",
    "num_samples_valid = len(valDict)#x_valid.shape[0]\n",
    "num_batches_valid = num_samples_valid // batch_size\n",
    "num_classes = len(trainList[1])\n",
    "\n",
    "fileNames_train = np.array([x[1] for x in trainDict.values()])\n",
    "targets_train = np.array([catIdToTargetDict[x[0]] for x in trainDict.values()])\n",
    "fileNames_valid = np.array([x[1] for x in valDict.values()])\n",
    "targets_valid = np.array([catIdToTargetDict[x[0]] for x in valDict.values()])\n",
    "imageShape = [3,224,224]\n",
    "\n",
    "\n",
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "test_acc, test_loss = [], []\n",
    "cur_loss = 0\n",
    "loss = []\n",
    "loss_valid = []\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        #Own code\n",
    "        cur_loss_d = 0\n",
    "        for i in range(num_batches_valid):\n",
    "            if i%10 == 0:\n",
    "                print i/float(num_batches_valid)*100\n",
    "            #print(i/float(num_batches_valid)*100)\n",
    "            idx_d = range(i*batch_size_valid, (i+1)*batch_size_valid)\n",
    "            filenames_batch_d = fileNames_valid[idx_d]\n",
    "            x_batch_d = imgReader('../../coco/val2014', filenames_batch_d,imageShape, MEAN_IMAGE)\n",
    "            target_batch_d = targets_valid[idx_d]    \n",
    "            batch_loss_d = f_val(x_batch_d,target_batch_d)\n",
    "            cur_loss_d += batch_loss_d[0]\n",
    "        loss_valid += [cur_loss_d/batch_size_valid]\n",
    "        print \"1 loop done\"\n",
    "        #Forward->Backprob->Update params\n",
    "        cur_loss = 0\n",
    "        for i in range(num_batches_train):\n",
    "            if i%10 == 0:\n",
    "                print i/float(num_batches_train)*100\n",
    "            #print(i/float(num_batches_train)*100)\n",
    "            idx = range(i*batch_size, (i+1)*batch_size)\n",
    "            filenames_batch = fileNames_train[idx]\n",
    "            x_batch = imgReader('../../coco/train2014', filenames_batch, imageShape, MEAN_IMAGE)\n",
    "            target_batch = targets_train[idx]    \n",
    "            batch_loss = f_train(x_batch,target_batch) #this will do the complete backprob pass\n",
    "            cur_loss += batch_loss[0]\n",
    "        loss += [cur_loss/batch_size]\n",
    "        print \"2 loop done\"\n",
    "\n",
    "        confusion_valid = ConfusionMatrix(num_classes)\n",
    "        confusion_train = ConfusionMatrix(num_classes)\n",
    "\n",
    "        for i in range(num_batches_train):\n",
    "            if i%10 == 0:\n",
    "                print i/float(num_batches_valid)*100\n",
    "            #print(i/float(num_batches_train)*100)\n",
    "            idx = range(i*batch_size, (i+1)*batch_size)\n",
    "            filenames_batch = fileNames_train[idx]\n",
    "            x_batch = imgReader('../../coco/train2014', filenames_batch, imageShape, MEAN_IMAGE)\n",
    "            targets_batch = targets_train[idx]\n",
    "            net_out = f_eval(x_batch)   \n",
    "            preds = np.argmax(net_out, axis=-1) \n",
    "            confusion_train.batch_add(targets_batch, preds)\n",
    "        print \"3 loop done\"\n",
    "        confusion_valid = ConfusionMatrix(num_classes)\n",
    "        for i in range(num_batches_valid):\n",
    "            if i%10 == 0:\n",
    "                print i/float(num_batches_valid)*100\n",
    "            #print(i/float(num_batches_valid)*100)\n",
    "            idx = range(i*batch_size_valid, (i+1)*batch_size_valid)\n",
    "            filenames_batch_d = fileNames_valid[idx_d]\n",
    "            x_batch = imgReader('../../coco/val2014', filenames_batch_d,imageShape, MEAN_IMAGE)\n",
    "            targets_batch = targets_valid[idx]\n",
    "            net_out = f_eval(x_batch)   \n",
    "            preds = np.argmax(net_out, axis=-1) \n",
    "\n",
    "            confusion_valid.batch_add(targets_batch, preds)\n",
    "        print \"4 loop done\"\n",
    "        train_acc_cur = confusion_train.accuracy()\n",
    "        valid_acc_cur = confusion_valid.accuracy()\n",
    "\n",
    "        train_acc += [train_acc_cur]\n",
    "        valid_acc += [valid_acc_cur]\n",
    "        print \"Epoch %i : Train Loss %e , Train acc %f,  Valid acc %f \" \\\n",
    "        % (epoch+1, loss[-1], train_acc_cur, valid_acc_cur)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "    \n",
    "\n",
    "#get test set score\n",
    "#confusion_test = ConfusionMatrix(num_classes)\n",
    "#net_out = f_eval(x_test)    \n",
    "#preds = np.argmax(net_out, axis=-1) \n",
    "#confusion_test.batch_add(targets_test, preds)\n",
    "#print \"\\nTest set Acc:  %f\" %(confusion_test.accuracy())\n",
    "\n",
    "\n",
    "epoch = np.arange(len(train_acc))\n",
    "plt.figure()\n",
    "plt.plot(epoch,train_acc,'r',epoch,valid_acc,'b')\n",
    "plt.legend(['Train Acc','Val Acc'])\n",
    "plt.xlabel('Epochs'), plt.ylabel('Acc'), plt.ylim([0.75,1.03])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epoch,loss,'r',epoch,loss_valid,'b')\n",
    "plt.legend(['Train Loss','Val Loss'])\n",
    "plt.xlabel('Epochs'), plt.ylabel('Loss'), plt.ylim([0,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch = np.arange(len(train_acc))\n",
    "plt.figure()\n",
    "plt.plot(epoch,train_acc,'r',epoch,valid_acc,'b')\n",
    "plt.legend(['Train Acc','Val Acc'])\n",
    "plt.xlabel('Epochs'), plt.ylabel('Acc'), plt.ylim([0, 0.1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epoch,loss,'r',epoch,loss_valid,'b')\n",
    "plt.legend(['Train Loss','Val Loss'])\n",
    "plt.xlabel('Epochs'), plt.ylabel('Loss'), plt.ylim([0,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#yo = os.listdir('../../coco/val2014')\n",
    "#'COCO_val2014_000000458311.jpg' in yo\n",
    "#print(\"val\" in 'COCO_val2014_000000458311.jpg')\n",
    "#for i in range(len(fileNames_train)):\n",
    "#    if \"val\" in fileNames_train[i]:\n",
    "#        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the model parameters and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 224, 224)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEAN_IMAGE[:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model[\"values\"][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Trying it out\n",
    "\n",
    "### Get some test images\n",
    "We'll download the ILSVRC2012 validation URLs and pick a few at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "index = urllib.urlopen('http://www.image-net.org/challenges/LSVRC/2012/ori_urls/indexval.html').read()\n",
    "image_urls = index.split('<br>')\n",
    "\n",
    "np.random.seed(25)\n",
    "np.random.shuffle(image_urls)\n",
    "image_urls = image_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_urls = [\"http://farm1.staticflickr.com/15/22703851_729cd2cd04.jpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper to fetch and preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import skimage.transform\n",
    "\n",
    "def prep_image(url):\n",
    "    ext = url.split('.')[-1]\n",
    "    im = plt.imread(io.BytesIO(urllib.urlopen(url).read()), ext)\n",
    "    # Resize so smallest dim = 256, preserving aspect ratio\n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        im = skimage.transform.resize(im, (256, w*256/h), preserve_range=True)\n",
    "    else:\n",
    "        im = skimage.transform.resize(im, (h*256/w, 256), preserve_range=True)\n",
    "\n",
    "    # Central crop to 224x224\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-112:h//2+112, w//2-112:w//2+112]\n",
    "    \n",
    "    rawim = np.copy(im).astype('uint8')\n",
    "    \n",
    "    # Shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    \n",
    "    # Convert to BGR\n",
    "    im = im[::-1, :, :]\n",
    "\n",
    "    im = im - MEAN_IMAGE\n",
    "    return rawim, floatX(im[np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process test images and print top 5 predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "for url in image_urls:\n",
    "    try:\n",
    "        #rawim, im = prep_image(url)\n",
    "        im = io.imread('%s/%s/%s'%(dataDir,'train2014',allFiles[16]))\n",
    "        rawim = np.copy(im).astype('uint8')\n",
    "        im = np.transpose(im,(2,0,1))\n",
    "        im = np.reshape(im,(1,3,224,224))\n",
    "        print(im.shape)\n",
    "        im = im - MEAN_IMAGE\n",
    "        prob = np.array(lasagne.layers.get_output(output_layer, im, deterministic=True).eval())\n",
    "        top5 = np.argsort(prob[0])[-1:-6:-1]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(rawim.astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        for n, label in enumerate(top5):\n",
    "            plt.text(250, 70 + n * 20, '{}. {}'.format(n+1, CLASSES[label]), fontsize=14)\n",
    "    except IOError:\n",
    "        print('bad url: ' + url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
